{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # results will be respoducible, \"it works on my machine\" won't make a good excuse :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling function [kids' code, you can try and improve it :)]\n",
    "def pooling(x, kernel=2, pool='avg'):\n",
    "    m, n = x.shape\n",
    "    k = kernel\n",
    "    mk = m // k\n",
    "    nk = n // k\n",
    "    \n",
    "    y = np.zeros((mk, nk))\n",
    "    for i in range(y.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            window = x[i*k:(i+1)*k,j*k:(j+1)*k]\n",
    "            if pool == 'avg':\n",
    "                y[i, j] = window.mean()\n",
    "            elif pool == 'max':\n",
    "                y[i, j] = window.max()\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = 0  # TODO: replace this with the last digit of you student's ID\n",
    "kernel = 2  # change this to 3 or 4 if you run into numerical stability problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'data'\n",
    "\n",
    "data_test = MNIST(\n",
    "    root = datapath, \n",
    "    train = False, \n",
    "    transform = ToTensor(),\n",
    ")\n",
    "\n",
    "x_data = [pooling(image.numpy().reshape(28, 28), kernel=kernel, pool='avg') for image, label in data_test if label==digit]\n",
    "x_data = np.asarray(x_data)\n",
    "x_data[x_data > .5] = 1\n",
    "x_data[x_data <= .5] = 0\n",
    "\n",
    "flatsize = (28//kernel)**2\n",
    "x_data = x_data.reshape(-1, flatsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Complete the code below\n",
    "\n",
    "Now it's your time to shine! \n",
    "You need to write the code to run the EM algorithm for a Bernoulli mixture and to sample for it.\n",
    "\n",
    "You can (1) do it from scrath or (2) use the skeleton of the class I have provided here.\n",
    "If you go for the 2nd option, you should write the code for\n",
    "- the static method `compute_log_bernoulli`, which returns the log-probabilities for multivariate Bernoulli distributions:\n",
    "\\begin{equation*}\n",
    "\\log p(x|\\mu) = \\sum_{j=1}^{d} x_{j} \\log \\mu_j + (1 - x_j) \\log \\mu_j\n",
    "\\end{equation*}\n",
    "These allow to compute responsibilities with better numerical stability. Static methods don't take `self` as input and are essentially equivalent to normal functions. \n",
    "- the `_em_step` method, which updates the parameters `self.pi` and `self.mu` of the Bernoulli mixture based on the input observations `x`.\n",
    "- the `sample` method, which returns `n` data points sampled from the Bernoulli mixture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMM:\n",
    "\n",
    "    \"\"\"\n",
    "    Class constructor\n",
    "\n",
    "    Parameters: \n",
    "    - n_components: number of Bernoulli vectors in the mixture (K)\n",
    "    - pi: initial array of priors/weights for each Bernoulli vector [shape: (K,)]\n",
    "          If None, the initial array is defined automatically based on the input of fit()\n",
    "    - mu: initial array of Bernoulli parameters, where each column refers to a different bernoulli vector [shape: (d, K)].\n",
    "          If None, the initial array is defined automatically based on the input of fit()\n",
    "    - alpha: stability parameter. Bernoulli parameters are constrained between\n",
    "    \"\"\"\n",
    "    def __init__(self, n_components=2, pi=None, mu=None, alpha=0.001) -> None:\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.pi = pi\n",
    "        self.mu = mu\n",
    "        self.alpha = alpha\n",
    "\n",
    "    \"\"\"\n",
    "    Method: _init_params\n",
    "\n",
    "    Initializes parameters\n",
    "    \"\"\"\n",
    "    def _init_params(self, x):\n",
    "        if self.pi is None:\n",
    "            self.pi = np.ones(self.n_components)/self.n_components\n",
    "        if self.mu is None:\n",
    "            self.mu = (1-self.alpha)*np.random.rand(x.shape[1], self.n_components)+self.alpha\n",
    "        return\n",
    "\n",
    "    \"\"\"\n",
    "    Methods: get_params\n",
    "\n",
    "    Returns a dictionary with all the BMM's parameters\n",
    "    \"\"\"\n",
    "    def get_params(self) -> dict:\n",
    "        return {\n",
    "            'pi': self.pi.copy(),\n",
    "            'mu': self.mu.copy(),\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_log_bernoulli(x, mu):\n",
    "        log_prob = np.zeros((x.shape[0], mu.shape[1]))  # allocate array of log-likelihoods\n",
    "        \n",
    "        # ++++++++++++++++++++++++\n",
    "        # TODO: Add your code here\n",
    "        # ++++++++++++++++++++++++\n",
    "\n",
    "        return log_prob\n",
    "\n",
    "    \"\"\"\n",
    "    Method: _em_step\n",
    "\n",
    "    Performs a single EM step based on the input x\n",
    "    \"\"\"\n",
    "    def _em_step(self, x):\n",
    "\n",
    "        # ++++++++++++++++++++++++\n",
    "        # TODO: Add your code here\n",
    "        # ++++++++++++++++++++++++\n",
    "\n",
    "        return\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Method: fit\n",
    "\n",
    "    Fits the Bernoulli mixture by repeating the EM steps and updating the parameters self.pi and self.mu \n",
    "    until convergence is reached\n",
    "\n",
    "    Parameters:\n",
    "    - x: Input data [shape (n, d)]\n",
    "    - eps: Convergence parameter, you can try and play with it\n",
    "    - max_iters: Maximum number of iterations\n",
    "    - verbose: if True, prints the parameters variation at each iteration\n",
    "    \"\"\"\n",
    "    def fit(self, x, eps=1, max_iters=100, verbose=False):\n",
    "\n",
    "        self._init_params(x)\n",
    "\n",
    "        converged = False\n",
    "        num_iters = 0\n",
    "\n",
    "        while (not converged):\n",
    "            \n",
    "            params_old = self.get_params()\n",
    "            self._em_step(x)  # perform EM step\n",
    "            params_new = self.get_params()\n",
    "            \n",
    "            converged = True\n",
    "\n",
    "            for name in params_old.keys():\n",
    "                # compute RMSE between old and new params\n",
    "                delta = np.sqrt(np.mean((params_new[name] - params_old[name])**2))\n",
    "                print(f\"Variation of {name} at iter {num_iters+1:03d}: {delta}\")\n",
    "                if delta > eps:\n",
    "                    converged = False\n",
    "\n",
    "            num_iters += 1\n",
    "\n",
    "            if num_iters >= max_iters:\n",
    "                if verbose:\n",
    "                    print(\"Maximum number of iterations reached: stop fitting.\")\n",
    "        return self\n",
    "\n",
    "    \"\"\"\n",
    "    Method: sample\n",
    "\n",
    "    Returns n datapoints sampled from the Bernoulli mixture [output shape: (n, d)]\n",
    "    \"\"\"\n",
    "    def sample(self, n):\n",
    "        samples = np.zeros(n, self.mu.shape[0])\n",
    "        # ++++++++++++++++++++++++\n",
    "        # TODO: Add your code here\n",
    "        # ++++++++++++++++++++++++\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmm = BMM(n_components=10).fit(x_data, eps=0.1, max_iters=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 10 images (flattened)\n",
    "x_sample = bmm.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir(f'results/{digit}'):\n",
    "    os.makedirs(f'results/{digit}')\n",
    "\n",
    "# plot the generated images and save them\n",
    "for i, x in enumerate(x_sample):\n",
    "    image = x.reshape(28//kernel, 28//kernel)\n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap='binary')\n",
    "    plt.savefig(f'results/{digit}/example_{i+1:03d}.png')\n",
    "    plt.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hy673",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "898d28840f55b3c5c9a615fda231169adc20c90e3e87a937f55caa36837c15d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
